from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.keys import Keys
import time
import os
import json
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from urllib.parse import quote

SITES = {
    "friends": {
        "base_url": "https://friends.smarticket.co.il/",
        "sheet_tab": "Friends"
    },
    "papi": {
        "base_url": "https://papi.smarticket.co.il/",
        "sheet_tab": "Papi"
    },}


def get_short_names():
    service_account_info = json.loads(os.environ["GOOGLE_SERVICE_ACCOUNT"])
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds = ServiceAccountCredentials.from_json_keyfile_dict(service_account_info, scope)
    client = gspread.authorize(creds)
    

    sheet = client.open("×“××˜×” ××¤×©×™×˜ ××•×¤×™×¡").worksheet("×”×¤×§×•×ª")
    short_names = sheet.col_values(2)  # for example, if "×©× ××§×•×¦×¨" is column B
    return [name for name in short_names if name and name != "×©× ××§×•×¦×¨"]

def get_driver():
    
    options = Options()
    options.add_argument("--headless=new")  # âœ… use headless mode
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920,1080")

    service = Service(executable_path="/usr/bin/chromedriver")
    driver = webdriver.Chrome(service=service, options=options)
    return driver

def scrape_site(site_config):
    base_url = site_config["base_url"]
    sheet_tab = site_config["sheet_tab"]
    print(f"ğŸŒ Starting scraper for site: {sheet_tab} ({base_url})")

    driver = get_driver()

    try:
        # Load show names from Google Sheets
        short_names = get_short_names()
        print(f"ğŸ” Loaded {len(short_names)} short names")

        for name in short_names[:5]:  # first 5 for testing
            print(f"â¡ï¸ Searching for: {name}")

            # Encode the show name for the URL
            search_url = f"{base_url}search?q={quote(name)}"
            
            try:
                driver.get(search_url)

                # Wait for results container to load
                WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, ".shows-list, .result-container"))
                )

                print(f"âœ… Finished search for: {name}")
                print("ğŸŒ Current URL:", driver.current_url)

            except Exception as inner_e:
                print(f"âŒ Error on show '{name}': {inner_e}")
                # Save a screenshot with the show name
                safe_name = name.replace(" ", "_").replace("/", "_")
                screenshot_path = f"screenshots/{sheet_tab}_{safe_name}.png"
                os.makedirs("screenshots", exist_ok=True)
                driver.save_screenshot(screenshot_path)
                print(f"ğŸ“¸ Screenshot saved to: {screenshot_path}")

    except Exception as e:
        print(f"âŒ Error while scraping {base_url}: {e}")
    finally:
        driver.quit()

# Run daily scrapers
for site in ["friends", "papi"]:
    scrape_site(SITES[site])